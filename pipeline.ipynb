{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dced01be-6927-415d-9058-5ed9053814e0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b22f3-4cda-4ffe-bc90-c3729de5d467",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7148f-f49c-400b-b283-f61e7728cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "from typing import List\n",
    "\n",
    "import pulp\n",
    "import cvxpy as cp\n",
    "import gurobipy as gp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import data_preparation\n",
    "from data import ppmi_data_loader\n",
    "from evaluation import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024299b5-83fe-4238-ba2c-5a096fc98b57",
   "metadata": {},
   "source": [
    "### Create encoded df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6096b3-f30b-425e-b2ed-7731f77d8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_self_reported(item):\n",
    "    for prefix in [\"NP1SLPN\", \"NP1SLPD\", \"NP1PAIN\", \"NP1URIN\", \"NP1CNST\", \"NP1LTHD\", \"NP1FATG\", \"NP2\"]:\n",
    "        if item.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df, items, all_items = data_preparation.get_encoded_df(include_moca=True)      \n",
    "self_reported_items = [item for item in all_items if is_self_reported(item)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336a87f-1537-41f5-9d49-457d695c5be5",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6a67a-4a33-4271-bde3-62c5e89d63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patnos = df.PATNO.unique().tolist()\n",
    "\n",
    "train_patients, test_patients = train_test_split(all_patnos, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = df[df['PATNO'].isin(train_patients)]\n",
    "test_df = df[df['PATNO'].isin(test_patients)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17137671-04f8-42be-964d-80a022a7a0bd",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0fd09b-fecd-4752-b9fd-acac80408096",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of items: {len(all_items)}\")\n",
    "print(f\"\\nNumber of self reported items: {len(self_reported_items)}\")\n",
    "print(f\"\\nTotal number of visits: {len(df)}\")\n",
    "print(f\"\\nTotal number of unique patients: {len(df.PATNO.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0a07f-8a3f-454e-91f9-d807ee057798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H&Y distribution\n",
    "print(f\"Ratio of visits with H&Y <=2: {len(df[df.NHY <= 2]) / len(df)}\")\n",
    "\n",
    "nhy_counts = pd.DataFrame({\n",
    "    'Train': train_df.NHY.value_counts(dropna=False).sort_index(),\n",
    "    'Test': test_df.NHY.value_counts(dropna=False).sort_index()\n",
    "})\n",
    "\n",
    "display(nhy_counts.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0bcaa-5e63-409c-98bf-ab2cf03f13b1",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e96fb-c8a1-4032-87a1-4cbf39640d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers.naive_p1_optimizer import NaiveP1Optimizer\n",
    "from optimizers.naive_p2_optimizer import NaiveP2Optimizer\n",
    "from optimizers.naive_p3_optimizer import NaiveP3Optimizer\n",
    "from optimizers.naive_mds_updrs_optimizer import NaiveMdsUpdrsOptimizer\n",
    "from optimizers.naive_moca_optimizer import NaiveMocaOptimizer\n",
    "from optimizers.linear_programming_optimizer import LinearProgrammingOptimizer\n",
    "from optimizers.weighted_linear_programming_optimizer import WeightedLinearProgrammingOptimizer\n",
    "from optimizers.quadratic_programming_optimizer import QuadraticProgrammingOptimizer\n",
    "from optimizers.mean_variance_balance_optimizer import MeanVarianceBalanceOptimizer\n",
    "from optimizers.mixed_integer_programming_optimizer import MixedIntegerProgrammingOptimizer\n",
    "from optimizers.integer_programming_optimizer import IntegerProgrammingOptimizer\n",
    "from optimizers.weights_optimizer import Status\n",
    "\n",
    "TIME_LIMIT = 86400  # 24 hours\n",
    "\n",
    "def create_optimizers(data, items, version):\n",
    "    \"\"\"Creates a list of optimizer instances.\"\"\"\n",
    "    return [\n",
    "        NaiveP1Optimizer(data=data, items=items, version=version),\n",
    "        NaiveP2Optimizer(data=data, items=items, version=version),\n",
    "        NaiveP3Optimizer(data=data, items=items, version=version),\n",
    "        NaiveMdsUpdrsOptimizer(data=data, items=items, version=version),\n",
    "        NaiveMocaOptimizer(data=data, items=items, version=version),\n",
    "        LinearProgrammingOptimizer(data=data, items=items, version=version, name='MeanDiff'),\n",
    "        WeightedLinearProgrammingOptimizer(data=data, items=items, version=version, name='MeanDiff-W'),\n",
    "        QuadraticProgrammingOptimizer(data=data, items=items, version=version, name='MeanDiff-QP'),\n",
    "        MeanVarianceBalanceOptimizer(data=data, items=items, version=version, name='MeanDiff-SV'),\n",
    "        MixedIntegerProgrammingOptimizer(data=data, items=items, time_limit=TIME_LIMIT, version=version, name='Cons'),\n",
    "        IntegerProgrammingOptimizer(data=data, items=items, time_limit=TIME_LIMIT, version=version, name='Cons-Int'),\n",
    "    ]\n",
    "\n",
    "def run_optimizers(optimizers):\n",
    "    \"\"\"Runs the optimization process for a list of optimizers, reusing results if already completed.\"\"\"\n",
    "    results = {}\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    for i, opt in enumerate(optimizers):\n",
    "        name = opt.get_name()\n",
    "        print(f\"[{i+1}/{len(optimizers)}] Starting {name}\")\n",
    "\n",
    "        # Check if the optimizer already completed successfully\n",
    "        status = opt.get_status()\n",
    "        if status == Status.DONE:\n",
    "            print(f\"{name} already completed. Retrieving stored weights.\")\n",
    "            weights = opt.get_weights()\n",
    "        else:\n",
    "            # Run the optimization process\n",
    "            start_time = time.time()\n",
    "            weights, status = opt.calc_weights()\n",
    "            run_time = time.time() - start_time\n",
    "            print(f\"{name} done.\\nStatus = {status}.\\nRuntime: {str(timedelta(seconds=run_time))}\")\n",
    "\n",
    "        # Save the results if not an error\n",
    "        if status != Status.ERROR:\n",
    "            results[name] = weights\n",
    "        else:\n",
    "            print(f\"Optimizer {name} failed.\")\n",
    "\n",
    "    total_run_time = time.time() - total_start_time\n",
    "    print(f\"Total runtime for all optimizers: {str(timedelta(seconds=total_run_time))}\")\n",
    "    return results\n",
    "\n",
    "optimizers_all_items = create_optimizers(data=train_df, items=all_items, version=\"all_items\")\n",
    "results_all_items = run_optimizers(optimizers_all_items)\n",
    "\n",
    "optimizers_self_report = create_optimizers(data=train_df, items=self_reported_items, version=\"self_reported\")\n",
    "results_self_report = run_optimizers(optimizers_self_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7193044-6bd8-43d5-9974-b18e07c4d258",
   "metadata": {},
   "source": [
    "### Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce013d-6c84-44b4-97bb-e8af562ba540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current epoch timestamp\n",
    "timestamp = int(time.time())\n",
    "\n",
    "# Convert the results_all_items dict to a DataFrame with 'item' as the first column\n",
    "df_all_items = pd.DataFrame({'item': all_items, **results_all_items})\n",
    "\n",
    "# Convert the results_self_report dict to a DataFrame with 'item' as the first column\n",
    "df_self_report = pd.DataFrame({'item': self_reported_items, **results_self_report})\n",
    "\n",
    "# Save the DataFrames as CSV files with the timestamp in the filename\n",
    "df_all_items.to_csv(f'optimizers/weights/all_items_weights_{timestamp}.csv', index=False)\n",
    "df_self_report.to_csv(f'optimizers/weights/self_report_weights_{timestamp}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072feec-f57f-4176-a7b5-229b1ed77882",
   "metadata": {},
   "source": [
    "### Load weights (Optional)\n",
    "\n",
    "To examine weights calculated in a previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ef796-90af-44e3-9ac4-a2c311eadf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = '123456789'  # The timestamp when version was saved\n",
    "\n",
    "# df_all_items = pd.read_csv(f'optimizers/weights/all_items_weights_{version}.csv')\n",
    "# df_self_report = pd.read_csv(f'optimizers/weights/self_report_weights_{version}.csv')\n",
    "\n",
    "# results_all_items = {col: df_all_items[col].tolist() for col in df_all_items.columns if col != 'item'}\n",
    "# results_self_report = {col: df_self_report[col].tolist() for col in df_self_report.columns if col != 'item'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b00d3a-d0f6-4b90-9df4-e7fad04b4ffa",
   "metadata": {},
   "source": [
    "## Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc7138-8625-4d08-8b90-abcb8db3ba9b",
   "metadata": {},
   "source": [
    "### Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137f344-5c49-4e75-b3f0-8d607faacb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the consistency tables\n",
    "\n",
    "evaluator_all_items = Evaluator(test_df=test_df, all_items=all_items)\n",
    "evaluator_self_report = Evaluator(test_df=test_df, all_items=self_reported_items)\n",
    "\n",
    "num_pairs_all = evaluator_all_items.get_num_pairs()\n",
    "num_pairs_self_report = evaluator_self_report.get_num_pairs()\n",
    "\n",
    "# Convert months to years\n",
    "num_pairs_all.index = num_pairs_all.index // 12\n",
    "num_pairs_self_report.index = num_pairs_self_report.index // 12\n",
    "\n",
    "# Ignore rows with more than 10 years gaps (too scarce)\n",
    "num_pairs_all = num_pairs_all[num_pairs_all.index <= 10]\n",
    "num_pairs_self_report = num_pairs_self_report[num_pairs_self_report.index <= 10]\n",
    "\n",
    "data_all_items = {\"Number of Pairs\": num_pairs_all}\n",
    "data_self_report = {\"Number of Pairs\": num_pairs_self_report}\n",
    "\n",
    "# All Items\n",
    "total_weighted_avg_all = {}\n",
    "for name, res in results_all_items.items():\n",
    "    percentage_scores_pos = evaluator_all_items.get_increase_percentages(res)\n",
    "    percentage_scores_pos.index = percentage_scores_pos.index // 12\n",
    "    percentage_scores_pos = percentage_scores_pos[percentage_scores_pos.index <= 10]\n",
    "    data_all_items[name] = percentage_scores_pos\n",
    "    total_weighted_avg_all[name] = (percentage_scores_pos * num_pairs_all).sum() / num_pairs_all.sum()\n",
    "\n",
    "# Self-Reported Items\n",
    "total_weighted_avg_self = {}\n",
    "for name, res in results_self_report.items():\n",
    "    percentage_scores_pos = evaluator_self_report.get_increase_percentages(res)\n",
    "    percentage_scores_pos.index = percentage_scores_pos.index // 12\n",
    "    percentage_scores_pos = percentage_scores_pos[percentage_scores_pos.index <= 10]\n",
    "    data_self_report[name] = percentage_scores_pos\n",
    "    \n",
    "    total_weighted_avg_self[name] = (percentage_scores_pos * num_pairs_self_report).sum() / num_pairs_self_report.sum()\n",
    "\n",
    "inc_all_items_df = pd.DataFrame(data_all_items).sort_index()\n",
    "inc_self_report_df = pd.DataFrame(data_self_report).sort_index()\n",
    "\n",
    "inc_all_items_df.index.name = \"Years Gap\"\n",
    "inc_self_report_df.index.name = \"Years Gap\"\n",
    "\n",
    "weighted_avg_all_df = pd.DataFrame.from_dict(total_weighted_avg_all, orient='index', columns=[\"Total Weighted Increase (%)\"])\n",
    "weighted_avg_self_df = pd.DataFrame.from_dict(total_weighted_avg_self, orient='index', columns=[\"Total Weighted Increase (%)\"])\n",
    "\n",
    "all_items_cons_table = inc_all_items_df.copy()\n",
    "self_reported_items_cons_table = inc_self_report_df.copy()\n",
    "all_items_cons_table.loc['All'] = [num_pairs_all.sum()] + list(total_weighted_avg_all.values())\n",
    "self_reported_items_cons_table.loc['All'] = [num_pairs_self_report.sum()] + list(total_weighted_avg_self.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d8cd74-254d-4ad3-af29-b454ec06a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the consistency for each method and time gap for methods using all items\n",
    "display(all_items_cons_table.round(2).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e737198-e2ef-446b-80be-24f565e1475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the consistency for each method and time gap for methods using only self reported items\n",
    "display(self_reported_items_cons_table.round(2).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef90f11-e0d3-4560-844e-db83d27e2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare MDS-UPDRS to MeanDiff-QP using all items or only self reported items\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "blue_colors = sns.color_palette(\"Blues\", 2)\n",
    "green_colors = sns.color_palette(\"Oranges\", 2)\n",
    "\n",
    "sns.lineplot(data=inc_all_items_df['MDS-UPDRS'], label=f'MDS-UPDRS (All Items)', ax=ax, linestyle='--', color=blue_colors[0])\n",
    "sns.lineplot(data=inc_self_report_df['MDS-UPDRS'], label=f'MDS-UPDRS (Self-Reported)', ax=ax, linestyle='--', color=green_colors[0])\n",
    "sns.lineplot(data=inc_all_items_df['MeanDiff-QP'], label=f'MeanDiff-QP (All Items)', ax=ax, linestyle='-', color=blue_colors[1])\n",
    "sns.lineplot(data=inc_self_report_df['MeanDiff-QP'], label=f'MeanDiff-QP (Self-Reported)', ax=ax, linestyle='-', color=green_colors[1])\n",
    "\n",
    "ax.set_xlabel('Time gap (years)')\n",
    "ax.set_xticks(inc_all_items_df.index)\n",
    "ax.set_ylabel('Percentage of consistent pairs')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba812c-9fab-41d3-af47-96a015535fc4",
   "metadata": {},
   "source": [
    "### Consistency vs parsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f191b-9614-44d7-9994-51b1e1b6ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pareto_df(weighted_avg_df, results_dict):\n",
    "    # Extract 'Total Weighted Increase (%)' for each method\n",
    "    consistency = weighted_avg_df['Total Weighted Increase (%)']\n",
    "\n",
    "    # Count non-zero weights for each method\n",
    "    non_zero = {method: sum(1 for w in weights if w != 0) for method, weights in results_dict.items()}\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    pareto_df = pd.DataFrame({\n",
    "        'consistency': consistency,\n",
    "        'non_zero': pd.Series(non_zero)\n",
    "    }).reset_index()\n",
    "\n",
    "    return pareto_df\n",
    "\n",
    "# Creating Pareto DataFrames\n",
    "pareto_all_items_df = create_pareto_df(weighted_avg_all_df, results_all_items)\n",
    "pareto_self_reported_df = create_pareto_df(weighted_avg_self_df, results_self_report)\n",
    "\n",
    "# Remove methods irrelevant for self report\n",
    "pareto_self_reported_df = pareto_self_reported_df[pareto_self_reported_df.non_zero > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe4fbe-ddd2-451b-8da9-f791efbcd7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the consistency and sparsity of all method using all items\n",
    "display(pareto_all_items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e1e9a-af9c-43b7-8688-f20fc31fea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the consistency and sparsity of all method using only self reported items\n",
    "display(pareto_self_reported_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe0f53a-d2b8-4823-a586-19cf92dc42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Pareto frontiers \n",
    "unique_methods = sorted(set(pareto_all_items_df['index']).union(set(pareto_self_reported_df['index'])))\n",
    "markers = dict(zip(unique_methods, ['^', '^', 's', 's', 's', 's', 'p', 'p', 'p', 'p', 'D'][:len(unique_methods)]))\n",
    "orange_colors = sns.color_palette(\"Oranges_r\", 5)\n",
    "green_colors = sns.color_palette(\"summer\", 6)\n",
    "\n",
    "# Assign colors based on markers\n",
    "palette = {}\n",
    "for i, method in enumerate(unique_methods):\n",
    "    if markers[method] in {'s', 'D'}:\n",
    "        palette[method] = orange_colors.pop(0)  # Assign a deep orange color\n",
    "    else:\n",
    "        palette[method] = green_colors.pop(0)  # Assign a strong greenish color\n",
    "\n",
    "\n",
    "def plot_pareto_frontier(ax, df, title):\n",
    "    scatter = sns.scatterplot(data=df, x='non_zero', y='consistency', hue='index', style='index', \n",
    "                              s=300, ax=ax, palette=palette, markers=markers)\n",
    "\n",
    "    pareto_front = df.sort_values('non_zero').copy()\n",
    "    pareto_front['Pareto'] = pareto_front['consistency'].cummax()\n",
    "    pareto_points = pareto_front[pareto_front['consistency'] == pareto_front['Pareto']]\n",
    "\n",
    "    ax.plot(pareto_points['non_zero'], pareto_points['consistency'], color='red', linestyle='--', label='Pareto Frontier')\n",
    "\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_xlabel('Number of Non-zero Items', fontsize=16)\n",
    "    ax.set_ylabel('Consistent Pairs Percentage', fontsize=16)\n",
    "\n",
    "    return scatter  # Return scatterplot to extract legend handles and labels\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8), sharey=True)\n",
    "\n",
    "scatter = plot_pareto_frontier(axes[0], pareto_all_items_df, 'All Items - Pareto Frontier')\n",
    "plot_pareto_frontier(axes[1], pareto_self_reported_df.drop(columns=[]), 'Self-Reported Items - Pareto Frontier')\n",
    "\n",
    "axes[0].get_legend().remove()\n",
    "axes[1].get_legend().remove()\n",
    "\n",
    "handles, labels = scatter.get_legend_handles_labels()\n",
    "\n",
    "# Place a single legend in between the two plots\n",
    "fig.legend(handles, labels, loc='lower center', fontsize=20, markerscale=2, ncol=3, frameon=True, bbox_to_anchor=(0.5, 0.1))\n",
    "\n",
    "# Add subplot labels\n",
    "axes[0].text(0.05, 1.05, 'A', transform=axes[0].transAxes, fontsize=20, fontweight='bold', va='top', ha='right')\n",
    "axes[1].text(0.05, 1.05, 'B', transform=axes[1].transAxes, fontsize=20, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c44d2b-f62d-4f5e-a3c3-84804c7448fe",
   "metadata": {},
   "source": [
    "### Compare to external metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490f450-30f1-4b13-bc4e-053a8d675fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ppmi_data_loader.PpmiDataLoader(ppmi_dir='data/PPMI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee88e0-7507-4a19-a1a1-5606f134098e",
   "metadata": {},
   "source": [
    "#### Time to levodopa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d41c83-742a-4d7c-b0fa-535cffb8cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dopaminergic_data(dop_df):\n",
    "    dop_df['INFODT'] = pd.to_datetime(dop_df['INFODT'], format='%m/%Y')\n",
    "    dop_df = dop_df.sort_values(by=['PATNO', 'INFODT'])\n",
    "    \n",
    "    def get_levodopa_start(group):\n",
    "        if (group['DOPTHERST'] == 0).any():\n",
    "            first_start = group[group['DOPTHERST'] == 1].head(1)\n",
    "            return first_start\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    levodopa_start_df = dop_df.groupby('PATNO').apply(get_levodopa_start).reset_index(drop=True)\n",
    "    return levodopa_start_df.groupby('PATNO')['INFODT'].min().to_dict()\n",
    "\n",
    "def apply_levodopa_dates(test_df_copy, earliest_dates):\n",
    "    \"\"\"\n",
    "    Apply the earliest levodopa start dates to the test data.\n",
    "    \"\"\"\n",
    "    test_df_copy.loc[:, 'levodopa_start_date'] = test_df_copy['PATNO'].map(earliest_dates)\n",
    "    test_df_copy.loc[:, 'time_diff'] = (test_df_copy['levodopa_start_date'] - test_df_copy['INFODT']).dt.days\n",
    "    return test_df_copy.dropna(subset=['time_diff'])\n",
    "\n",
    "def calc_correlations(final_scores_df, df_weights, prefix, methods):\n",
    "    for i, method in enumerate(methods):\n",
    "        x = final_scores_df[final_scores_df['method'] == method]['time_diff'].dropna()\n",
    "        y = final_scores_df[final_scores_df['method'] == method]['total_score'].dropna()\n",
    "        r, p = pearsonr(x, y)\n",
    "        print(f'{prefix}, {method}: rho={r}, p={p}')\n",
    "\n",
    "dop_df = dl.get_dopa_start_df()\n",
    "earliest_dates = process_dopaminergic_data(dop_df)\n",
    "\n",
    "weighted_scores_all_items_df = evaluator_all_items.calculate_all_weighted_scores(df_all_items)\n",
    "weighted_scores_all_items_df = apply_levodopa_dates(weighted_scores_all_items_df, earliest_dates)\n",
    "\n",
    "weighted_scores_self_report_df = evaluator_self_report.calculate_all_weighted_scores(df_self_report)\n",
    "weighted_scores_self_report_df = apply_levodopa_dates(weighted_scores_self_report_df, earliest_dates)\n",
    "\n",
    "all_methods = inc_all_items_df.columns.tolist()[1:]\n",
    "self_reported_methods = [m for m in all_methods if m not in ['MDS-UPDRS Part 3', 'MoCA']]\n",
    "\n",
    "calc_correlations(weighted_scores_all_items_df, df_all_items, prefix='All Items', methods=all_methods)\n",
    "calc_correlations(weighted_scores_self_report_df, df_self_report, prefix='Self-Reported Items', methods=self_reported_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa032e7-adfc-4592-a703-c35febebf116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def plot_selected_methods(final_scores_df, method, title, label, ax):\n",
    "    \"\"\"\n",
    "    Plots a single method's scores vs. years before levodopa treatment on a given axis,\n",
    "    with a trend line.\n",
    "    \"\"\"\n",
    "    x = final_scores_df[final_scores_df['method'] == method]['time_diff'].dropna() / 365.25\n",
    "    y = final_scores_df[final_scores_df['method'] == method]['total_score'].dropna()\n",
    "\n",
    "    r, p = pearsonr(x, y)\n",
    "    ax.scatter(x, y, label=f'{method} {title}', color='blue')\n",
    "\n",
    "    # Fit and plot a trend line\n",
    "    coeffs = np.polyfit(x, y, 1)  # Linear fit\n",
    "    poly_eq = np.poly1d(coeffs)\n",
    "    x_fit = np.linspace(min(x), max(x), 100)\n",
    "    y_fit = poly_eq(x_fit)\n",
    "    ax.plot(x_fit, y_fit, linestyle='--', color='red', label='Trend Line')\n",
    "\n",
    "    ax.text(0.05, 0.05, f'Pearson ρ: {r:.2f}\\np: {p:.2e}', \n",
    "            verticalalignment='bottom', horizontalalignment='left', \n",
    "            transform=ax.transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "    ax.set_title(f'{method} ({title})\\nScores vs. Years Before Treatment', fontsize=18)\n",
    "    ax.set_xlabel('Years Before Levodopa', fontsize=16)\n",
    "    ax.set_ylabel(f'{method} Score', fontsize=16)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add subplot label ('A' or 'B') in top-left corner\n",
    "    ax.text(0.04, 1.06, label, transform=ax.transAxes, fontsize=20, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))  # No 'sharey=True' here\n",
    "\n",
    "# Plot 'MeanDiff-QP' for all items (left plot, labeled 'A')\n",
    "plot_selected_methods(weighted_scores_all_items_df, 'MeanDiff-QP', 'All Items', 'A', axes[0])\n",
    "\n",
    "# Plot 'Cons-Int' for self-reported items (right plot, labeled 'B')\n",
    "plot_selected_methods(weighted_scores_self_report_df, 'Cons-Int', 'Self-Reported Items', 'B', axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0713e3be-cedd-455c-bf3e-c0647887057d",
   "metadata": {},
   "source": [
    "#### S&E ADL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56276698-557d-4e2e-beef-e4f64a8eb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_adl_df = dl.get_se_adl_df()\n",
    "se_adl_df['INFODT'] = pd.to_datetime(se_adl_df['INFODT'], format='%m/%Y')\n",
    "\n",
    "test_df_copy = test_df.copy()\n",
    "filtered_df = test_df_copy.merge(se_adl_df, on=['PATNO', 'EVENT_ID', 'INFODT'], how='inner')\n",
    "\n",
    "def calculate_weighted_scores(row, weights_df):\n",
    "    \"\"\"\n",
    "    Calculate the weighted sum for each weighting method for a given row.\n",
    "    \"\"\"\n",
    "    weighted_scores = {}\n",
    "    for method in weights_df.columns[1:]:\n",
    "        weights = weights_df.set_index('item')[method]\n",
    "        weighted_scores[method] = sum(row[item] * weights[item] for item in weights.index if item in row.index)\n",
    "    return pd.Series(weighted_scores)\n",
    "\n",
    "def calc_correlations(filtered_df, df_weights, prefix):\n",
    "    \"\"\"\n",
    "    Apply the weighted score calculation and plot for a given set of weights (df_weights).\n",
    "    \"\"\"\n",
    "    # Apply the weighted score calculation for each row\n",
    "    weighted_scores_df = filtered_df.apply(lambda row: calculate_weighted_scores(row, df_weights), axis=1)\n",
    "\n",
    "    # Combine the results with SE ADL data\n",
    "    final_df = pd.concat([filtered_df[['PATNO', 'INFODT', 'MSEADLG']], weighted_scores_df], axis=1)\n",
    "\n",
    "    for i, method in enumerate(df_weights.columns[1:]):\n",
    "        x = final_df['MSEADLG']\n",
    "        y = final_df[method]\n",
    "        \n",
    "        data = final_df[['MSEADLG', method]].copy()\n",
    "        \n",
    "        if not data.empty and not all(data[method] == data[method].iloc[0]):\n",
    "            # r, p = spearmanr(data['MSEADLG'], data[method])\n",
    "            r, p = pearsonr(data['MSEADLG'], data[method])\n",
    "            print(f'{prefix}, {method}: rho={r}, p={p}')\n",
    "\n",
    "calc_correlations(filtered_df, df_all_items, 'All Items')\n",
    "calc_correlations(filtered_df, df_self_report, 'Self-Reported Items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d7702-17f3-4cfe-ba42-d079e5343d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute Weighted Scores First\n",
    "def compute_weighted_scores(filtered_df, df_weights):\n",
    "    \"\"\"\n",
    "    Computes the weighted sum for each method in df_weights.\n",
    "    \"\"\"\n",
    "    weighted_scores_df = filtered_df.apply(lambda row: calculate_weighted_scores(row, df_weights), axis=1)\n",
    "    return pd.concat([filtered_df[['PATNO', 'INFODT', 'MSEADLG']], weighted_scores_df], axis=1)\n",
    "\n",
    "weighted_adl_all_items_df = compute_weighted_scores(filtered_df, df_all_items)\n",
    "weighted_adl_self_report_df = compute_weighted_scores(filtered_df, df_self_report)\n",
    "\n",
    "def plot_selected_adl_methods(weighted_df, method, title, label, ax):\n",
    "    \"\"\"\n",
    "    Plots a single method's scores vs. S&E ADL score on a given axis.\n",
    "    \"\"\"\n",
    "    if method not in weighted_df.columns:\n",
    "        print(f\"Warning: Method '{method}' not found in dataframe columns.\")\n",
    "        ax.text(0.5, 0.5, 'No data available', horizontalalignment='center', \n",
    "                verticalalignment='center', transform=ax.transAxes, fontsize=14)\n",
    "        return\n",
    "\n",
    "    x = weighted_df['MSEADLG']\n",
    "    y = weighted_df[method]\n",
    "\n",
    "    data = weighted_df[['MSEADLG', method]].dropna()\n",
    "\n",
    "    # Filter groups with at least 5 data points\n",
    "    filtered_data = data.groupby('MSEADLG').filter(lambda x: len(x) >= 5)\n",
    "\n",
    "    # Calculate Spearman correlation\n",
    "    r, p = pearsonr(data['MSEADLG'], data[method])\n",
    "\n",
    "    # Plot boxplot\n",
    "    sns.boxplot(x='MSEADLG', y=method, data=filtered_data, ax=ax, color='skyblue')\n",
    "\n",
    "    # Add correlation text\n",
    "    ax.text(0.95, 0.05, f'Pearson ρ: {r:.2f}\\np: {p:.2e}',\n",
    "            verticalalignment='bottom', horizontalalignment='right',\n",
    "            transform=ax.transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "    # Title with two lines\n",
    "    ax.set_title(f'{method} ({title})\\nScores vs. S&E ADL Score', fontsize=18)\n",
    "    ax.set_xlabel('S&E ADL Score', fontsize=16)\n",
    "    ax.set_ylabel(f'{method} Score', fontsize=16)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add subplot label ('A' or 'B')\n",
    "    ax.text(0.04, 1.06, label, transform=ax.transAxes, fontsize=20, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "plot_selected_adl_methods(weighted_adl_all_items_df, 'MeanDiff-QP', 'All Items', 'A', axes[0])\n",
    "plot_selected_adl_methods(weighted_adl_self_report_df, 'MeanDiff-QP', 'Self-Reported Items', 'B', axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f59bee-c4fc-41b9-ac72-b122ce95ee0f",
   "metadata": {},
   "source": [
    "#### Time to milestone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55237f4-cf6d-45dd-b83c-106ce2323558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relevant data for milestoen calculation\n",
    "\n",
    "scopa_aut_df = pd.read_csv('data/PPMI/non_motor_assessments/SCOPA-AUT_07Aug2024.csv')\n",
    "scopa_aut_df = scopa_aut_df.drop(columns=['REC_ID', 'PAG_NAME', 'INFODT', 'PTCGBOTH','ORIG_ENTRY', 'LAST_UPDATE'])\n",
    "merged_df = pd.merge(df, scopa_aut_df, on=['PATNO','EVENT_ID'], how='inner')\n",
    "\n",
    "moca_df = pd.read_csv('data/PPMI/non_motor_assessments/Montreal_Cognitive_Assessment__MoCA__07Aug2024.csv')\n",
    "moca_df = moca_df[['PATNO', 'EVENT_ID', 'MCATOT']]\n",
    "merged_df = pd.merge(merged_df, moca_df, on=['PATNO','EVENT_ID'], how='inner')\n",
    "\n",
    "se_df = pd.read_csv('data/PPMI/motor_assessments/Modified_Schwab___England_Activities_of_Daily_Living_07Aug2024.csv')\n",
    "se_df = se_df[['PATNO', 'EVENT_ID', 'MSEADLG']]\n",
    "merged_df = pd.merge(merged_df, se_df, on=['PATNO','EVENT_ID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5c987-a673-4b0c-9603-22302bdebe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add milestones\n",
    "\n",
    "merged_df['milestone_scopa_aut_syncope'] = (merged_df.SCAU16 >= 1).astype(int)\n",
    "merged_df['milestone_orthostatic_hypotension'] = (merged_df.SCAU15 >= 2).astype(int)\n",
    "merged_df['milestone_urinary_incontinence'] = ((merged_df.NP1URIN_th3 == 1) & ((merged_df.SCAU8 >= 2) | (merged_df.SCAU9 >= 2))).astype(int)\n",
    "merged_df['milestone_moca'] = (merged_df.MCATOT < 21).astype(int)\n",
    "merged_df['milestone_h_and_y'] = (merged_df.NHY >= 4).astype(int)\n",
    "merged_df['milestone_s_and_e'] = (merged_df.MSEADLG < 80).astype(int)\n",
    "\n",
    "milestone_cols = [\"NP2WALK_th3\",\n",
    "                  \"NP2FREZ_th3\",\n",
    "                  \"NP3GAIT_th3\",\n",
    "                  \"NP3FRZGT_th4\",\n",
    "                  \"NP3PSTBL_th3\",\n",
    "                  \"NP1COG_th3\",\n",
    "                  \"NP1HALL_th3\",\n",
    "                  \"NP1APAT_th3\",\n",
    "                  \"NP1LTHD_th4\",\n",
    "                  \"NP2SWAL_th3\",\n",
    "                  \"NP2EAT_th3\",\n",
    "                  \"NP2DRES_th3\",\n",
    "                  \"NP2HYGN_th3\",\n",
    "                  \"NP3SPCH_th3\",\n",
    "                 ]\n",
    "\n",
    "additional_milestones = [\"milestone_moca\",\n",
    "                         \"milestone_scopa_aut_syncope\",\n",
    "                         \"milestone_orthostatic_hypotension\",\n",
    "                         \"milestone_urinary_incontinence\",\n",
    "                         \"milestone_h_and_y\",\n",
    "                         \"milestone_s_and_e\",\n",
    "                        ]\n",
    "milestone_cols.extend(additional_milestones)\n",
    "merged_df['any_milestone'] = merged_df[milestone_cols].max(axis=1)\n",
    "milestone_cols.append('any_milestone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ac9d8-3e4f-4332-80fc-9b24854c6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_items_indexed = df_all_items.set_index('item')\n",
    "all_methods = df_all_items_indexed.columns\n",
    "\n",
    "all_items_results = {}\n",
    "for method in all_methods:\n",
    "    all_items_results[method + \" (all)\"] = merged_df[df_all_items_indexed.index].dot(df_all_items_indexed[method])\n",
    "\n",
    "merged_df = pd.concat([merged_df, pd.DataFrame(all_items_results)], axis=1)\n",
    "\n",
    "df_self_report_indexed = df_self_report.set_index('item')\n",
    "self_reported_methods = [method for method in all_methods if method not in ['MDS-UPDRS Part 3', 'MoCA']]\n",
    "\n",
    "self_report_results = {}\n",
    "for method in self_reported_methods:\n",
    "    self_report_results[method + \" (self_reported)\"] = merged_df[df_self_report_indexed.index].dot(df_self_report_indexed[method])\n",
    "\n",
    "merged_df = pd.concat([merged_df, pd.DataFrame(self_report_results)], axis=1)\n",
    "\n",
    "methods = [c for c in merged_df.columns if c.endswith('(all)') or c.endswith('(self_reported)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e27a776-b995-47ed-82c3-db6a7006b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_to_milestone(grp):\n",
    "    \"\"\"\n",
    "    grp is the subset of df for a single PATNO, sorted by visit_month.\n",
    "    We'll return that group with a new 'time_to_milestone' column\n",
    "    using the rule:\n",
    "      - 0 if this row's any_milestone == 1\n",
    "      - (earliest_milestone_month - visit_month) if the row is before the first milestone\n",
    "      - NaN if the row is after the first milestone\n",
    "      - NaN if the patient never reaches a milestone\n",
    "    \"\"\"\n",
    "    milestone_months = grp.loc[grp[\"any_milestone\"] == 1, \"visit_month\"]\n",
    "    \n",
    "    if milestone_months.empty:\n",
    "        # No milestone at all -> all NaN\n",
    "        return grp.assign(time_to_milestone=float(\"nan\"))\n",
    "\n",
    "    first_milestone_month = milestone_months.min()\n",
    "    \n",
    "    # Vectorized computation\n",
    "    time_to_milestone = (\n",
    "        (first_milestone_month - grp[\"visit_month\"])\n",
    "        .where(grp[\"visit_month\"] < first_milestone_month, float(\"nan\"))\n",
    "    )\n",
    "    time_to_milestone.loc[grp[\"any_milestone\"] == 1] = 0  # Milestone visits are zero\n",
    "\n",
    "    return grp.assign(time_to_milestone=time_to_milestone)\n",
    "\n",
    "# Apply function patient-by-patient\n",
    "merged_df = (\n",
    "    merged_df\n",
    "    .sort_values([\"PATNO\", \"visit_month\"])\n",
    "    .groupby(\"PATNO\", group_keys=False)\n",
    "    .apply(calculate_time_to_milestone)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3886b-81f8-4ed5-8c05-721fa0132f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = merged_df.dropna(subset=[\"time_to_milestone\"]).copy()\n",
    "\n",
    "all_items_methods = [method + ' (all)' for method in all_methods]\n",
    "rs = []\n",
    "\n",
    "for method in methods:\n",
    "    df_method = df_valid.dropna(subset=[method])\n",
    "    r, p_value = pearsonr(df_method[\"time_to_milestone\"], df_method[method])\n",
    "    if method in all_items_methods:\n",
    "        rs.append(r)\n",
    "    print(f'{method}: rho={r}, p={p_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e340a-db23-4145-810a-dee4d946b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare correlations of methods using all items\n",
    "\n",
    "ax = sns.barplot(y=all_methods, x=rs, palette='Wistia')\n",
    "ax.vlines(x = min(rs[:5]), ymin = -.5, ymax = 10.5, linestyle='dashed', color='red')\n",
    "ax.set_xlabel('Correlation coefficient')\n",
    "plt.title(\"Correlation coefficients between progression index and time to milestone\", x=0.38)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
